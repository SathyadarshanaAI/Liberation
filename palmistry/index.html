<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>üïâÔ∏è TruePalm AI Analyzer ¬∑ V32.0 Mobile Camera Fixed Build</title>

  <!-- üß† OpenCV Library -->
  <script async src="https://docs.opencv.org/4.x/opencv.js"></script>

  <!-- ‚úÖ Mobile Console (Eruda) -->
  <script src="https://cdn.jsdelivr.net/npm/eruda"></script>
  <script>eruda.init();</script>

  <style>
    body { background:#0a0a0a; color:#fff; font-family:sans-serif; text-align:center; }
    h1 { color:#00ffff; }
    .block { border:1px solid #0ff; border-radius:15px; margin:15px; padding:10px; }
    button { margin:5px; padding:8px 14px; border:none; border-radius:10px; background:#0ff3; color:#fff; }
    canvas, video { width:90%; max-width:350px; border-radius:12px; margin-top:10px; }
    pre { text-align:left; background:#0003; border-radius:10px; padding:10px; }
    #status { margin-top:10px; color:#0ff; font-weight:bold; }
  </style>
</head>
<body>
  <h1>TruePalm AI Analyzer ¬∑ Stage 2</h1>
  <div id="status">üß© Initializing...</div>

  <!-- ‚úã LEFT HAND -->
  <div class="block">
    <h3>‚úã Left Hand</h3>
    <video id="vidLeft" autoplay muted playsinline></video><br/>
    <canvas id="canvasLeft" width="320" height="240"></canvas><br/>
    <button id="startCamLeft">Start Camera</button>
    <button id="captureLeft">Capture</button>
    <button id="analyzeLeft">Analyze Palm</button>
    <pre id="miniReportLeft"></pre>
    <pre id="deepReportLeft"></pre>
  </div>

  <!-- ü§ö RIGHT HAND -->
  <div class="block">
    <h3>ü§ö Right Hand</h3>
    <video id="vidRight" autoplay muted playsinline></video><br/>
    <canvas id="canvasRight" width="320" height="240"></canvas><br/>
    <button id="startCamRight">Start Camera</button>
    <button id="captureRight">Capture</button>
    <button id="analyzeRight">Analyze Palm</button>
    <pre id="miniReportRight"></pre>
    <pre id="deepReportRight"></pre>
  </div>

  <script type="module">
    import { detectPalmEdges } from './edgeLines.js';

    function cap(s){return s.charAt(0).toUpperCase()+s.slice(1);}

    async function waitForOpenCV(){
      return new Promise(resolve=>{
        const check=setInterval(()=>{
          if(window.cv && cv.Mat){clearInterval(check);resolve(true);}
        },500);
      });
    }

    async function initPalmAnalyzer(){
      await waitForOpenCV();
      document.getElementById('status').textContent='‚úÖ OpenCV Ready';
      console.log("‚úÖ OpenCV loaded:", window.cv);

      const hands=["left","right"];
      let streams={};

      for(const side of hands){
        const video=document.getElementById(`vid${cap(side)}`);
        const canvas=document.getElementById(`canvas${cap(side)}`);
        const ctx=canvas.getContext("2d");

        // ‚úÖ Camera Start
        document.getElementById(`startCam${cap(side)}`).onclick = async () => {
          document.getElementById("status").textContent = `üîÑ Trying to access ${side} camera...`;
          try {
            const constraints = {
              video: {
                facingMode: side === "left" ? "user" : "environment" // front / back
              }
            };
            console.log("üé• Camera constraints:", constraints);

            const stream = await navigator.mediaDevices.getUserMedia(constraints);
            video.srcObject = stream;
            streams[side] = stream;

            document.getElementById("status").textContent = `üì∑ ${side.toUpperCase()} camera running`;
            console.log(`‚úÖ ${side} camera started successfully`, stream);

          } catch (e) {
            console.error("Camera error:", e);
            alert("‚ö†Ô∏è Camera error: " + e.message + "\nPlease refresh and allow camera permission again.");
          }
        };

        // üñºÔ∏è Capture Image
        document.getElementById(`capture${cap(side)}`).onclick=()=>{
          if(!streams[side])return alert("Start camera first!");
          ctx.drawImage(video,0,0,canvas.width,canvas.height);
          video.pause();
          document.getElementById("status").textContent=`üì∏ ${side} captured`;
          console.log(`üñºÔ∏è ${side} image captured`);
        };

        // üß† Analyze Palm
        document.getElementById(`analyze${cap(side)}`).onclick=async()=>{
          document.getElementById("status").textContent=`üß† Analyzing ${side} hand...`;
          const frame=ctx.getImageData(0,0,canvas.width,canvas.height);
          try {
            const analysis=await detectPalmEdges(frame,canvas);
            const mini=`Life line: ${analysis.life}\nHeart line: ${analysis.heart}\nFate line: ${analysis.fate}`;
            const deep=`Palm shows ${analysis.heart}, ${analysis.fate}, ${analysis.life}. Emotional balance and inner strength are stable.`;
            document.getElementById(`miniReport${cap(side)}`).textContent=mini;
            document.getElementById(`deepReport${cap(side)}`).textContent=deep;

            const msg=side==="left"
              ?`‡∂î‡∂∫‡∑è‡∂ú‡∑ö ‡∑Ä‡∂∏‡∑ä ‡∂Ö‡∂≠‡∑ö ‡∂ª‡∑ö‡∂õ‡∑è ${analysis.life} ‡∂Ω‡∑ô‡∑É ‡∂¥‡∑ô‡∂±‡∑ô‡∂±‡∑ä‡∂±‡∑ô. ‡∂í‡∂ö ‡∑Å‡∂ö‡∑ä‡∂≠‡∑í‡∂∏‡∂≠‡∑ä ‡∂Ü‡∂≠‡∑ä‡∂∏ ‡∑Å‡∂ö‡∑ä‡∂≠‡∑í‡∂∫‡∂ö‡∑ä ‡∂¥‡∑ô‡∂±‡∑ä‡∑Ä‡∂∫‡∑í.`
              :`‡∂î‡∂∫‡∑è‡∂ú‡∑ö ‡∂Ø‡∂ö‡∑î‡∂´‡∑î ‡∂Ö‡∂≠‡∑ö ‡∂ª‡∑ö‡∂õ‡∑è ${analysis.heart} ‡∂Ω‡∑ô‡∑É ‡∂¥‡∑ô‡∂±‡∑ô‡∂±‡∑ä‡∂±‡∑ô. ‡∂í‡∂ö ‡∑Ä‡∑í‡∑Å‡∑ä‡∑Ä‡∑è‡∑É ‡∑É‡∑Ñ ‡∂±‡∑è‡∂∫‡∂ö‡∂≠‡∑ä‡∑Ä ‡∂ú‡∑î‡∂´ ‡∂¥‡∑ô‡∂±‡∑ä‡∑Ä‡∂∫‡∑í.`;
            const u=new SpeechSynthesisUtterance(msg);
            u.lang="si-LK";u.pitch=1;u.rate=1;
            speechSynthesis.speak(u);

            document.getElementById("status").textContent="‚ú® AI Analysis complete!";
          } catch(err){
            console.error("Palm analysis failed:",err);
            document.getElementById("status").textContent="‚ö†Ô∏è Analysis error ‚Äî try recapturing.";
          }
        };
      }
    }

    initPalmAnalyzer();
  </script>
</body>
</html>
