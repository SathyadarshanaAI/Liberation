<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>üïâÔ∏è TruePalm AI Analyzer ¬∑ V27.5 Stable Final Build</title>

  <!-- üß† TensorFlow.js -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.10.0/dist/tf.min.js"></script>

  <!-- üß© OpenCV.js -->
  <script async src="https://docs.opencv.org/4.x/opencv.js"></script>

  <style>
    body {
      background: #0a0a0a;
      color: #fff;
      font-family: sans-serif;
      text-align: center;
    }
    h1 {
      color: #00ffff;
      margin: 12px;
    }
    .block {
      border: 1px solid #0ff;
      border-radius: 15px;
      margin: 15px;
      padding: 10px;
    }
    button {
      margin: 5px;
      padding: 8px 14px;
      border: none;
      border-radius: 10px;
      background: #00ffff33;
      color: #fff;
      font-weight: bold;
    }
    video, canvas {
      width: 90%;
      max-width: 340px;
      border-radius: 10px;
      margin-top: 10px;
      border: 1px solid #00ffff55;
    }
    pre {
      text-align: left;
      background: #0005;
      border-radius: 8px;
      padding: 8px;
      color: #0ff;
      font-size: 0.9em;
    }
    #status {
      margin-top: 10px;
      color: #00ffff;
      font-weight: bold;
    }
  </style>
</head>
<body>
  <h1>üïâÔ∏è TruePalm AI Analyzer</h1>
  <div id="status">üß© Initializing...</div>

  <!-- ‚úã Left Hand -->
  <div class="block">
    <h3>‚úã Left Hand</h3>
    <video id="vidLeft" autoplay muted playsinline></video><br/>
    <canvas id="canvasLeft" width="320" height="240"></canvas><br/>
    <button id="startCamLeft">Start Camera</button>
    <button id="captureLeft">Capture</button>
    <button id="analyzeLeft">Analyze Palm</button>
    <pre id="analysisTextLeft"></pre>
  </div>

  <!-- ü§ö Right Hand -->
  <div class="block">
    <h3>ü§ö Right Hand</h3>
    <video id="vidRight" autoplay muted playsinline></video><br/>
    <canvas id="canvasRight" width="320" height="240"></canvas><br/>
    <button id="startCamRight">Start Camera</button>
    <button id="captureRight">Capture</button>
    <button id="analyzeRight">Analyze Palm</button>
    <pre id="analysisTextRight"></pre>
  </div>

<script>
/* ==============================================
   üïâÔ∏è TruePalm AI Analyzer ‚Äì Stable V27.5
   ============================================== */

// üß† Initialize TensorFlow (Optional)
async function initTF() {
  try {
    await tf.setBackend('webgl');
    await tf.ready();
    document.getElementById('status').textContent = '‚úÖ TensorFlow Ready';
    console.log('‚úÖ TensorFlow Ready');
  } catch (err) {
    console.warn('‚ö†Ô∏è TensorFlow init failed:', err);
  }
}

// üì∑ Start Camera
async function startCamera(videoId, facing="environment") {
  const video = document.getElementById(videoId);
  try {
    const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: facing } });
    video.srcObject = stream;
    await video.play();
    document.getElementById('status').textContent = `üì∑ Camera active (${facing})`;
  } catch (err) {
    alert("‚ö†Ô∏è Camera Error: " + err.message);
  }
}

// üñºÔ∏è Capture Frame
function captureFrame(videoId, canvasId) {
  const video = document.getElementById(videoId);
  const canvas = document.getElementById(canvasId);
  const ctx = canvas.getContext('2d');
  if (!video.srcObject) return alert("Start camera first!");
  ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
  video.pause();
  document.getElementById('status').textContent = "üì∏ Frame captured!";
}

// üß† Analyze Palm (Mock Report)
function analyzePalm(canvasId, reportId, side) {
  const canvas = document.getElementById(canvasId);
  const ctx = canvas.getContext('2d');
  const frame = ctx.getImageData(0, 0, canvas.width, canvas.height);

  if (!frame) return alert("Capture a palm image first!");

  // üß© OpenCV edge visualization
  if (window.cv && cv.Mat) {
    const mat = cv.matFromImageData(frame);
    let gray = new cv.Mat();
    cv.cvtColor(mat, gray, cv.COLOR_RGBA2GRAY);
    let blur = new cv.Mat();
    cv.GaussianBlur(gray, blur, new cv.Size(5,5), 0);
    let edges = new cv.Mat();
    cv.Canny(blur, edges, 40, 150);
    cv.imshow(canvas, edges);
    mat.delete(); gray.delete(); blur.delete(); edges.delete();
  }

  // üßò Mock AI Reading
  const report = `
Life Line: Strong & Balanced
Heart Line: Deep & Gentle
Fate Line: Rising Steady
  `;
  document.getElementById(reportId).textContent = report;
  document.getElementById('status').textContent = "‚ú® Palm Analyzed";

  // üéôÔ∏è Sinhala Voice Output
  const msg = side === "left"
    ? "‡∂î‡∂∫‡∑è‡∂ú‡∑ö ‡∑Ä‡∂∏‡∑ä ‡∂Ö‡∂≠‡∑ö ‡∂ª‡∑ö‡∂õ‡∑è ‡∑Å‡∂ö‡∑ä‡∂≠‡∑í‡∂∏‡∂≠‡∑ä ‡∑É‡∑Ñ ‡∂¥‡∑í‡∂ª‡∑í‡∑É‡∑í‡∂Ø‡∑î‡∂∫‡∑í."
    : "‡∂î‡∂∫‡∑è‡∂ú‡∑ö ‡∂Ø‡∂ö‡∑î‡∂´‡∑î ‡∂Ö‡∂≠‡∑ö ‡∂ª‡∑ö‡∂õ‡∑è ‡∑Ä‡∑í‡∑Å‡∑ä‡∑Ä‡∑è‡∑É ‡∑É‡∑Ñ ‡∂±‡∑è‡∂∫‡∂ö‡∂≠‡∑ä‡∑Ä ‡∂ú‡∑î‡∂´ ‡∂¥‡∑ô‡∂±‡∑ä‡∑Ä‡∂∫‡∑í.";
  const u = new SpeechSynthesisUtterance(msg);
  u.lang = "si-LK";
  u.pitch = 1;
  u.rate = 1;
  speechSynthesis.speak(u);
}

// ü™∑ Event Listeners
document.getElementById("startCamLeft").onclick = () => startCamera("vidLeft", "user");
document.getElementById("startCamRight").onclick = () => startCamera("vidRight", "environment");
document.getElementById("captureLeft").onclick = () => captureFrame("vidLeft", "canvasLeft");
document.getElementById("captureRight").onclick = () => captureFrame("vidRight", "canvasRight");
document.getElementById("analyzeLeft").onclick = () => analyzePalm("canvasLeft", "analysisTextLeft", "left");
document.getElementById("analyzeRight").onclick = () => analyzePalm("canvasRight", "analysisTextRight", "right");

initTF();
</script>
</body>
</html>
