<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<meta name="viewport" content="width=device-width,initial-scale=1"/>
<title>Palmistry AI Overlay ‚Äì Sathyadarshana</title>
<style>
:root{--pri:#16f0a7;--bg:#0b0f16;--neon:#00e5ff}
body{margin:0;background:var(--bg);color:#e6f0ff;font-family:system-ui;text-align:center}
h1{margin:14px 0 6px}
video,canvas{width:92vw;max-width:420px;border-radius:16px;border:2px solid var(--pri);display:block;margin:auto;background:#000}
.overlay{position:absolute;inset:0;pointer-events:none;opacity:.6}
.captureBtn{
 position:absolute;bottom:18px;left:50%;transform:translateX(-50%);
 width:85px;height:85px;border-radius:50%;
 border:none;background:#2196f3;color:#000;font-weight:600;
 box-shadow:0 0 15px #2196f333;cursor:pointer;
}
.btns{margin:10px 0;display:flex;gap:8px;justify-content:center;flex-wrap:wrap}
button{border:none;border-radius:8px;padding:.6em 1em;font-weight:700;cursor:pointer}
.left{background:#16243a;color:#cfe9ff}
.an{background:var(--pri);color:#000}
.cap{background:#fbbf24;color:#111}
.torch{background:#22c55e;color:#021}
.sliderRow{display:flex;gap:8px;justify-content:center;align-items:center;flex-wrap:wrap;margin-bottom:10px}
footer{color:var(--pri);margin:18px 0 22px;font-size:.9em}
</style>
<script>
(function(){
 const s=document.createElement('script');
 s.src="https://docs.opencv.org/4.x/opencv.js"; s.async=true;
 s.onload=()=>console.log("‚úÖ OpenCV loaded");
 s.onerror=()=>{const f=document.createElement('script');
 f.src="https://cdn.jsdelivr.net/npm/@techstark/opencv-js@4.9.0-1/opencv.min.js";
 f.async=true;f.onload=()=>console.log("‚úÖ Fallback OpenCV ready");document.head.appendChild(f);};
 document.head.appendChild(s);
})();
</script>
</head>
<body>
<h1>üñêÔ∏è Palmistry</h1>
<p>Align palm ‚Üí Capture ‚Üí Analyze</p>

<div class="wrap" style="position:relative;display:inline-block">
  <video id="cam" playsinline></video>
  <canvas id="cv"></canvas>
  <svg class="overlay" viewBox="0 0 420 560" preserveAspectRatio="xMidYMid slice">
    <path d="M145 485c-55-35-78-139-19-190 6-45 8-90 29-98 
             22-9 34 33 34 79 0-52 16-96 37-95 21 1 22 47 17 98 
             7-50 24-89 43-85 19 4 19 54 9 101 8-43 25-73 42-67 
             16 6 14 49 0 96 24 22 36 71 21 110-21 55-80 74-213 51z"
          fill="none" stroke="var(--neon)" stroke-width="2" filter="drop-shadow(0 0 5px var(--neon))"/>
  </svg>
  <button class="captureBtn" id="capBtn">Tap to Capture</button>
</div>

<div class="btns">
  <button class="left" id="flipBtn">üñê Left ¬∑ Past</button>
  <button class="torch" id="torchBtn" hidden>üî¶ Torch</button>
  <button class="an" id="anBtn">‚ú® Analyze</button>
  <button class="cap" id="saveBtn">üíæ Save</button>
</div>

<div class="sliderRow">
  <label>Edge <input id="edge" type="range" min="30" max="120" value="70"/></label>
  <label>Detail <input id="gk" type="range" min="3" max="15" step="2" value="9"/></label>
</div>

<footer>¬© 2025 Sathyadarshana ¬∑ Palmistry AI Overlay</footer>

<script>
const video=document.getElementById('cam'),canvas=document.getElementById('cv'),ctx=canvas.getContext('2d');
const flipBtn=document.getElementById('flipBtn'),capBtn=document.getElementById('capBtn'),
      anBtn=document.getElementById('anBtn'),saveBtn=document.getElementById('saveBtn'),torchBtn=document.getElementById('torchBtn');
let flipped=false,captured=false,stream=null,track=null,torch=false;

flipBtn.onclick=()=>{flipped=!flipped;video.style.transform=flipped?'scaleX(-1)':'none';};

async function ensureCamera(){
 if(stream) return;
 stream=await navigator.mediaDevices.getUserMedia({video:{facingMode:'environment'}});
 video.srcObject=stream; await video.play();
 track=stream.getVideoTracks()[0];
 const caps=track.getCapabilities?.(); if(caps && caps.torch) torchBtn.hidden=false;
}

torchBtn.onclick=async()=>{if(!track)return;torch=!torch;
 try{await track.applyConstraints({advanced:[{torch}]});}catch{}};

capBtn.onclick=async()=>{
 await ensureCamera();
 canvas.width=video.videoWidth; canvas.height=video.videoHeight;
 ctx.save(); if(flipped){ctx.translate(canvas.width,0);ctx.scale(-1,1);} ctx.drawImage(video,0,0,canvas.width,canvas.height); ctx.restore();
 captured=true;
};

saveBtn.onclick=()=>{if(!captured)return;const a=document.createElement('a');a.href=canvas.toDataURL('image/png');a.download='palm_'+Date.now()+'.png';a.click();};

anBtn.onclick=()=>{if(!captured)return alert('Capture first');if(!window.cv||!cv.Mat)return alert('OpenCV not ready');analyze();};

function analyze(){
 try{
   const src=cv.imread(canvas);
   const gray=new cv.Mat();cv.cvtColor(src,gray,cv.COLOR_RGBA2GRAY);
   const clahe=new cv.CLAHE(2.0,new cv.Size(8,8));clahe.apply(gray,gray);
   const sobelX=new cv.Mat(),sobelY=new cv.Mat(),edges=new cv.Mat();
   cv.Sobel(gray,sobelX,cv.CV_16S,1,0,3);cv.Sobel(gray,sobelY,cv.CV_16S,0,1,3);
   cv.convertScaleAbs(sobelX,sobelX);cv.convertScaleAbs(sobelY,sobelY);
   cv.addWeighted(sobelX,0.5,sobelY,0.5,0,edges);
   const bin=new cv.Mat();cv.adaptiveThreshold(edges,bin,255,cv.ADAPTIVE_THRESH_MEAN_C,cv.THRESH_BINARY,11,2);
   const kernel=cv.getStructuringElement(cv.MORPH_RECT,new cv.Size(3,3));
   cv.morphologyEx(bin,bin,cv.MORPH_OPEN,kernel);cv.dilate(bin,bin,kernel);
   const contours=new cv.MatVector(),hier=new cv.Mat();
   cv.findContours(bin,contours,hier,cv.RETR_EXTERNAL,cv.CHAIN_APPROX_SIMPLE);
   const out=src.clone();
   for(let i=0;i<contours.size();i++){
     const area=cv.contourArea(contours.get(i)); if(area<80)continue;
     cv.drawContours(out,contours,i,new cv.Scalar(0,255,0,255),2);
   }
   cv.imshow(canvas,out);
   [src,gray,clahe,sobelX,sobelY,edges,bin,kernel,contours,hier,out].forEach(m=>m.delete());
 }catch(e){alert('Error: '+e.message);}
}
</script>
</body>
</html>
