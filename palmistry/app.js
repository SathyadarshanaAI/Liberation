// === Basic DOM setup ===
const $ = id => document.getElementById(id);
const statusEl = $("status");
const reportBox = $("reportBox");
const leftVid = $("vidLeft"), rightVid = $("vidRight");
const leftCv = $("canvasLeft"), rightCv = $("canvasRight");

function msg(t, ok=true){ statusEl.textContent=t; statusEl.style.color=ok?"#16f0a7":"#ff6b6b"; }

// === Start Camera ===
async function startCam(side){
  const video = side==="left"?leftVid:rightVid;
  try{
    const stream = await navigator.mediaDevices.getUserMedia({video:{facingMode:"environment"},audio:false});
    video.srcObject=stream;
    await video.play();
    msg(`${side} camera started âœ…`);
  }catch(e){ msg(`Camera error: ${e.message}`, false); }
}

// === Capture and Analyze ===
async function analyze(side){
  const video = side==="left"?leftVid:rightVid;
  const canvas = side==="left"?leftCv:rightCv;
  const ctx = canvas.getContext("2d");
  canvas.width = video.videoWidth; canvas.height = video.videoHeight;
  ctx.drawImage(video,0,0,canvas.width,canvas.height);

  msg(`Analyzing ${side} hand...`);
  const data = ctx.getImageData(0,0,canvas.width,canvas.height);

  // --- Simple AI heuristic (placeholder until ONNX model integrated) ---
  const brightness = avgBrightness(data.data);
  const clarity = edgeStrength(data.data);
  const lifeLine = interpretLine(clarity,brightness);
  const heartLine = interpretEmotion(clarity,brightness);
  const fateLine = interpretDestiny(brightness,clarity);

  const report = `
ğŸ“– Palmistry Report (${side} hand)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸŒ¿ Life Line : ${lifeLine}
ğŸ’“ Heart Line : ${heartLine}
âš–ï¸ Fate Line : ${fateLine}
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Overall Clarity: ${clarity.toFixed(2)} | Light Balance: ${brightness.toFixed(2)}
âœ¨ Interpretation generated by Buddhi AI Palm Analyzer
`;

  reportBox.textContent = report;
  msg(`âœ… ${side} hand analyzed.`);
  speak(report);
}

// === Utility functions ===
function avgBrightness(data){
  let sum=0; for(let i=0;i<data.length;i+=4){ sum += (data[i]+data[i+1]+data[i+2])/3; }
  return sum/(data.length/4)/255;
}
function edgeStrength(data){
  let e=0; for(let i=0;i<data.length;i+=16){ e += Math.abs(data[i]-data[i+4]) + Math.abs(data[i+1]-data[i+5]); }
  return e/(data.length/16)/255;
}

// --- Interpretation heuristics ---
function interpretLine(c,b){
  if(c>0.45 && b<0.5) return "Strong vitality, balanced life energy.";
  if(c>0.45 && b>0.5) return "Energetic but needs grounding.";
  if(c<0.3) return "Low physical energy, conserve strength.";
  return "Stable and enduring nature.";
}
function interpretEmotion(c,b){
  if(b>0.6) return "Sensitive, emotionally expressive.";
  if(c>0.5) return "Calm and compassionate heart.";
  return "Reserved but loyal feelings.";
}
function interpretDestiny(b,c){
  if(c>0.55) return "Determined and disciplined destiny.";
  if(b>0.55) return "Flexible fate, creative freedom.";
  return "Still forming path â€” introspection needed.";
}

// === Voice narration ===
function speak(text){
  try{
    const synth = window.speechSynthesis;
    const utter = new SpeechSynthesisUtterance(text);
    utter.rate = 1.0; utter.pitch = 1.1;
    utter.lang = 'en-US';
    synth.cancel(); synth.speak(utter);
  }catch(e){ console.warn("Voice synthesis error", e); }
}

// === Bind buttons ===
$("startLeft").onclick = ()=>startCam("left");
$("startRight").onclick = ()=>startCam("right");
$("captureLeft").onclick = ()=>analyze("left");
$("captureRight").onclick = ()=>analyze("right");

// === Init ===
(async()=>{
  if(!navigator.mediaDevices){ msg("Camera not supported âŒ",false);}
  else msg("Ready. Click Start, then Analyze âœ¨");
})();
