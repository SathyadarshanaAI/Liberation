const $ = id => document.getElementById(id);
const statusEl = $("status");
const reportBox = $("reportBox");
const leftVid = $("vidLeft"), rightVid = $("vidRight");
const leftCv = $("canvasLeft"), rightCv = $("canvasRight");

function msg(t, ok = true) {
  statusEl.textContent = t;
  statusEl.style.color = ok ? "#16f0a7" : "#ff6b6b";
}

// --- Start camera ---
async function startCam(side) {
  const video = side === "left" ? leftVid : rightVid;
  try {
    const stream = await navigator.mediaDevices.getUserMedia({
      video: { facingMode: "environment" }, audio: false
    });
    video.srcObject = stream;
    await video.play();
    msg(`${side} camera started âœ…`);
  } catch (e) {
    msg(`Camera error: ${e.message}`, false);
  }
}

// --- Capture + Analyze ---
async function analyze(side) {
  const video = side === "left" ? leftVid : rightVid;
  const canvas = side === "left" ? leftCv : rightCv;
  const ctx = canvas.getContext("2d");

  canvas.width = video.videoWidth;
  canvas.height = video.videoHeight;
  ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

  msg(`Analyzing ${side} hand...`);
  const data = ctx.getImageData(0, 0, canvas.width, canvas.height);

  // --- basic analysis (brightness + edge clarity) ---
  const brightness = avgBrightness(data.data);
  const clarity = edgeStrength(data.data);
  const lifeLine = interpretLife(clarity, brightness);
  const heartLine = interpretHeart(clarity, brightness);
  const fateLine = interpretFate(brightness, clarity);

  const report = `
ğŸ“– Palmistry Report (${side} hand)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸŒ¿ Life Line : ${lifeLine}
ğŸ’“ Heart Line : ${heartLine}
âš–ï¸ Fate Line : ${fateLine}
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Overall Clarity: ${clarity.toFixed(2)} | Light Balance: ${brightness.toFixed(2)}
âœ¨ Interpretation generated by Buddhi AI Palm Analyzer
`;

  reportBox.textContent = report;
  msg(`âœ… ${side} hand analysis complete`);
  speak(report);
}

// --- helpers ---
function avgBrightness(d) {
  let s = 0;
  for (let i = 0; i < d.length; i += 4) s += (d[i] + d[i + 1] + d[i + 2]) / 3;
  return s / (d.length / 4) / 255;
}
function edgeStrength(d) {
  let e = 0;
  for (let i = 0; i < d.length; i += 16)
    e += Math.abs(d[i] - d[i + 4]) + Math.abs(d[i + 1] - d[i + 5]);
  return e / (d.length / 16) / 255;
}

function interpretLife(c, b) {
  if (c > 0.45 && b < 0.5) return "Strong vitality and balanced life energy.";
  if (c > 0.45 && b > 0.5) return "Energetic but needs rest and grounding.";
  if (c < 0.3) return "Low physical energy, conserve strength.";
  return "Stable and enduring life rhythm.";
}
function interpretHeart(c, b) {
  if (b > 0.6) return "Sensitive and emotionally expressive.";
  if (c > 0.5) return "Calm, caring, and compassionate heart.";
  return "Quiet but loyal emotions.";
}
function interpretFate(b, c) {
  if (c > 0.55) return "Determined and disciplined destiny.";
  if (b > 0.55) return "Creative, flexible fate path.";
  return "Path forming â€” deep reflection advised.";
}

// --- Voice narration ---
function speak(txt) {
  try {
    const synth = window.speechSynthesis;
    const u = new SpeechSynthesisUtterance(txt);
    u.lang = "en-US"; u.rate = 1; u.pitch = 1.1;
    synth.cancel(); synth.speak(u);
  } catch (e) { console.warn("Speech error", e); }
}

// --- Bind ---
$("startLeft").onclick = () => startCam("left");
$("startRight").onclick = () => startCam("right");
$("captureLeft").onclick = () => analyze("left");
$("captureRight").onclick = () => analyze("right");

// --- Init ---
(async () => {
  if (!navigator.mediaDevices) msg("Camera not supported âŒ", false);
  else msg("Ready. Click Start â†’ Analyze âœ¨");
})();
